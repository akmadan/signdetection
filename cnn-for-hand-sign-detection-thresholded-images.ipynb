{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntraining_set = train_datagen.flow_from_directory('../input/hand-signs15-dataset-thresholded-images/dataset/train',\n                                                 target_size=(64, 64),\n                                                 batch_size=5,\n                                                 color_mode='grayscale',\n                                                 class_mode='categorical')\n\ntest_set = test_datagen.flow_from_directory('../input/hand-signs15-dataset-thresholded-images/dataset/test',\n                                            target_size=(64, 64),\n                                            batch_size=5,\n                                            color_mode='grayscale',\n                                            class_mode='categorical') ","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found 3244 images belonging to 5 classes.\nFound 815 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"classifier = Sequential()\n\nclassifier.add(Convolution2D(32, (3, 3), input_shape=(64, 64, 1), activation='relu'))\nclassifier.add(MaxPooling2D(pool_size=(2, 2)))\n\nclassifier.add(Convolution2D(32, (3, 3), activation='relu'))\nclassifier.add(MaxPooling2D(pool_size=(2, 2)))\n\nclassifier.add(Flatten())\n\nclassifier.add(Dense(units=128, activation='relu'))\n\nclassifier.add(Dense(units=5, activation='softmax'))\n\nclassifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nprint(classifier.summary())","metadata":{"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_2 (Conv2D)            (None, 62, 62, 32)        320       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 31, 31, 32)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 29, 29, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 6272)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               802944    \n_________________________________________________________________\ndense_3 (Dense)              (None, 5)                 645       \n=================================================================\nTotal params: 813,157\nTrainable params: 813,157\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.optimizers import RMSprop,SGD,Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint('hand_gesture.h5',\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\n\nearlystop = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\ncallbacks = [earlystop,checkpoint,reduce_lr]\n\nclassifier.compile(loss='categorical_crossentropy',\n              optimizer = Adam(lr=0.001),\n              metrics=['accuracy'])\n\n\nepochs=10\n\nhistory=classifier.fit(\n                training_set,\n                steps_per_epoch=3244,\n                epochs=epochs,\n                callbacks=callbacks,\n                validation_data=test_set,\n                validation_steps=815)","metadata":{"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/10\n3244/3244 [==============================] - 17s 5ms/step - loss: 0.0919 - accuracy: 0.9698 - val_loss: 0.1923 - val_accuracy: 0.9153\n\nEpoch 00001: val_loss improved from inf to 0.19225, saving model to hand_gesture.h5\n","output_type":"stream"}]}]}